{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d416b489-90d1-445e-bf4c-15f55051ecf1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-11 21:35:14.750068: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-11 21:35:14.868934: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-11 21:35:14.868958: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-11 21:35:15.471006: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-11 21:35:15.471118: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-11 21:35:15.471126: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/caipengfei/mambaforge/envs/scCAT/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import scarlink as sl\n",
    "import scarlink.src.visualization as scv\n",
    "from scarlink.src.read_model import read_model\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import h5py\n",
    "import pandas\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90d14717-3929-4967-b91f-6ef76f59c978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/media/NaturalPopulationCohort/caipengfei/scCAT/SCARlink_analysis/downloaded'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../SCARlink_analysis/downloaded')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3911bcf-4ea1-4dab-b840-37eb5dc02a05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-11 16:13:03--  https://figshare.com/ndownloader/files/44297132?private_link=9b9e89ff3150aebb6d7a\n",
      "正在解析主机 figshare.com (figshare.com)... 34.248.40.228, 52.214.121.144, 2a05:d018:1f4:d003:e29a:4e34:ef7f:49e1, ...\n",
      "正在连接 figshare.com (figshare.com)|34.248.40.228|:443... 已连接。\n",
      "已发出 HTTP 请求，正在等待回应... 403 Forbidden\n",
      "2024-05-11 16:13:04 错误 403：Forbidden。\n",
      "\n",
      "Archive:  scripts.zip\n",
      "  End-of-central-directory signature not found.  Either this file is not\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
      "  latter case the central directory and zipfile comment will be found on\n",
      "  the last disk(s) of this archive.\n",
      "note:  scripts.zip may be a plain executable, not an archive\n",
      "unzip:  cannot find zipfile directory in one of scripts.zip or\n",
      "        scripts.zip.zip, and cannot find scripts.zip.ZIP, period.\n"
     ]
    }
   ],
   "source": [
    "### Download scripts from figshare\n",
    "!( \\\n",
    "if [ ! -d ./scripts ]; then \\\n",
    "wget https://figshare.com/ndownloader/files/44297132?private_link=9b9e89ff3150aebb6d7a -O ./scripts.zip; \\\n",
    "unzip scripts.zip; rm scripts.zip; \\\n",
    "fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5523384e-a82c-4838-a725-748f5ff721e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.compare_corrs import plot_compare_gsm_corr, plot_compare_dorc_corr\n",
    "from scripts.compare_corrs import make_gsm_scarlink_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6445b3b-9353-4b05-905a-b2926d1441b6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def calc_fishers_p(r12, r13, r23, n):\n",
    "    # adjust for numerical issues\n",
    "    det_s = max(0, 1 - (r12**2 + r13**2 + r23**2) + 2*r12*r13*r23)\n",
    "\n",
    "    t = (n-1)*(1+r23)\n",
    "    t /= 2*((n-1)/(n-3))*det_s + (r12+r13)**2/4*math.pow(1-r23, 3)\n",
    "    t = abs(r12-r13)*math.sqrt(t)\n",
    "    pval = stats.t.sf(t, n-3)\n",
    "    return pval\n",
    "\n",
    "def get_gsm_gene(gsm, gene_names, rm, gene):\n",
    "    # gsm: Gene score matrix with cell x gene score\n",
    "    # gene_names: Names of genes in columns\n",
    "\n",
    "    gene_gsm = np.ravel(gsm[gene_names['name'] == gene, :].todense())\n",
    "    return gene_gsm[rm.test_ix]\n",
    "\n",
    "def get_model_gene(rm, f, gene):\n",
    "    # get SCARlink predictions for given gene\n",
    "    w_mat = np.array(f['genes/' + gene][:])\n",
    "    e = np.array([f['genes/' + gene].attrs['intercept']])\n",
    "    params = [w_mat, e]\n",
    "    train_alpha = float(f['genes/' + gene].attrs['alpha'])\n",
    "    gex_train, gex_test = rm.get_gex_gene(gene)\n",
    "    tile_gene_mat_train, tile_gene_mat_test = rm.gene_tile_matrix_scaled(gene,\n",
    "                                                    normalization_factor='ReadsInTSS')\n",
    "    model_custom = rm.build_model(tile_gene_mat_test.shape[1], train_alpha)\n",
    "    model_custom.set_weights(params)\n",
    "    pred_vals = np.ravel(model_custom(tile_gene_mat_test.todense(), training=False).numpy())\n",
    "    return pred_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc5ec556-0308-4e76-ac1b-de61f51a0096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scarlink_table_DiffTechs(dirname1, dirname2, out_prefix, check_hvg=True):\n",
    "    # create table with Spearman correlations between predicted gene expression from SCARlink using different techniques\n",
    "\n",
    "    dirname1 = dirname1 + '/' if dirname1[-1] != '/' else dirname1\n",
    "    dirname2 = dirname2 + '/' if dirname2[-1] != '/' else dirname2\n",
    "\n",
    "    if check_hvg:\n",
    "        # Initially model was run on more genes. We are going to use two overlap genes\n",
    "        if os.path.isfile(dirname1 + 'hvg.txt'):\n",
    "            hvg1 = pandas.read_csv(dirname1 + 'hvg.txt', header=None)[0].values.tolist()\n",
    "        if os.path.isfile(dirname2 + 'hvg.txt'):\n",
    "            hvg2 = pandas.read_csv(dirname2 + 'hvg.txt', header=None)[0].values.tolist()\n",
    "        hvg=[i for i in hvg1 if i in hvg2]\n",
    "\n",
    "    dirname1 = dirname1 + \"scarlink_out/\"\n",
    "    dirname2 = dirname2 + \"scarlink_out/\"\n",
    "    filename = out_prefix + '_values.csv'\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        df = pandas.read_csv(filename, sep='\\t')\n",
    "        return df\n",
    "\n",
    "\n",
    "    coef_file_1 = dirname1 + 'coefficients_None.hd5'\n",
    "    coef_file_2 = dirname2 + 'coefficients_None.hd5'\n",
    "    \n",
    "    # tbl = pandas.DataFrame(columns=['gene', 'model_test_corr'])\n",
    "    model1_corrs = []\n",
    "    model2_corrs = []\n",
    "    \n",
    "    better_method = []\n",
    "    gene_name = []\n",
    "    \n",
    "    #model1_model2_corrs = []\n",
    "    #method_corr = []\n",
    "    \n",
    "    f1 = h5py.File(coef_file_1, mode = 'r')\n",
    "    f2 = h5py.File(coef_file_2, mode = 'r')\n",
    "    \n",
    "    f_genes1 = list(f1['genes/'].keys())\n",
    "    f_genes2 = list(f2['genes/'].keys())\n",
    "    f_genes=[i for i in f_genes1 if i in f_genes2]\n",
    "    \n",
    "    rm1 = read_model(dirname1, out_file_name=coef_file_1.split('/')[-1], read_only=True)\n",
    "    rm2 = read_model(dirname2, out_file_name=coef_file_2.split('/')[-1], read_only=True)\n",
    "        \n",
    "    if check_hvg and hvg != []:\n",
    "        f_genes = list(filter(lambda x: x in hvg, f_genes))\n",
    "\n",
    "    for gene in f_genes:\n",
    "        m1 = get_model_gene(rm1, f1, gene)\n",
    "        _, obs1 = rm1.get_gex_gene(gene)\n",
    "        obs1 = np.ravel(obs1.todense())\n",
    "        m1_obs, _ = stats.spearmanr(m1, obs1)\n",
    "        \n",
    "        m2 = get_model_gene(rm2, f2, gene)\n",
    "        _, obs2 = rm2.get_gex_gene(gene)\n",
    "        obs2 = np.ravel(obs2.todense())\n",
    "        m2_obs, _ = stats.spearmanr(m2, obs2)\n",
    "\n",
    "        #m1_m2, _ = stats.spearmanr(m1, m2)\n",
    "        \n",
    "        model1_corrs.append(m1_obs)\n",
    "        model2_corrs.append(m2_obs)\n",
    "        \n",
    "        #model1_model2_corrs.append(m1_m2)\n",
    "        #fishers_corr = calc_fishers_p(m_obs, g_obs, m_g, rm.test_ix.shape[0])\n",
    "        #method_corr.append(fishers_corr)\n",
    "        \n",
    "        gene_name.append(gene)\n",
    "        better_method.append(1 if m1_obs > m2_obs else -1)\n",
    "    f1.close()\n",
    "    f2.close()\n",
    "    \n",
    "    df = pandas.DataFrame(columns=['method 1', 'method 2', 'gene'])\n",
    "    df['method 1'] = model1_corrs\n",
    "    df['method 2'] = model2_corrs\n",
    "    df['gene'] = gene_name\n",
    "    df['better_method_flag'] = better_method\n",
    "    df.to_csv(filename, sep='\\t', index=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "300bb3a4-709f-4610-9fe7-680992286da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scarlink_table(dirname, check_hvg=True):\n",
    "    # create table with Spearman correlations between predicted gene expression from SCARlink\n",
    "\n",
    "    dirname = dirname + '/' if dirname[-1] != '/' else dirname\n",
    "\n",
    "    if check_hvg:\n",
    "        # Initially model was run on more genes. We are going to use two overlap genes\n",
    "        if os.path.isfile(dirname + 'hvg.txt'):\n",
    "            hvg = pandas.read_csv(dirname + 'hvg.txt', header=None)[0].values.tolist()\n",
    "        else:\n",
    "            hvg=[]\n",
    "\n",
    "    dirname = dirname + \"scarlink_out/\"\n",
    "    \n",
    "    coef_file = dirname + 'coefficients_None.hd5'\n",
    "    \n",
    "    model_corrs = []\n",
    "    gene_name = []\n",
    "    \n",
    "    f = h5py.File(coef_file, mode = 'r')\n",
    "    \n",
    "    f_genes = list(f['genes/'].keys())\n",
    "    \n",
    "    rm = read_model(dirname, out_file_name=coef_file.split('/')[-1], read_only=True)\n",
    "      \n",
    "    if check_hvg and hvg != []:\n",
    "        f_genes = list(filter(lambda x: x in hvg, f_genes))\n",
    "\n",
    "    for gene in f_genes:\n",
    "        m = get_model_gene(rm, f, gene)\n",
    "        _, obs = rm.get_gex_gene(gene)\n",
    "        obs = np.ravel(obs.todense())\n",
    "        m_obs, _ = stats.spearmanr(m, obs)\n",
    "        \n",
    "        model_corrs.append(m_obs)\n",
    "        \n",
    "        gene_name.append(gene)\n",
    "        \n",
    "    f.close()\n",
    "    \n",
    "    df = pandas.DataFrame(columns=['corr', 'gene'])\n",
    "    df['corr'] = model_corrs\n",
    "    df['gene'] = gene_name\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0405eb-4527-4f9d-82f4-6967bdb852f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_compare_gsm_corr(df, plot_title):\n",
    "    \n",
    "    print(\"Number of genes:\", df.shape)\n",
    "    min_val = np.nanmin(df[['method 1', 'method 2']].values)\n",
    "    max_val = np.nanmax(df[['method 1', 'method 2']].values)\n",
    "\n",
    "    pv = df['fishers_p'].values\n",
    "    pv[np.isnan(pv)] = 1\n",
    "    _, pv, _, _ = multipletests(pv, method='fdr_bh')\n",
    "\n",
    "    df['corr_significance_log'] = -np.log10(pv)\n",
    "    better_method = np.ones(df.shape[0])\n",
    "    better_method[(df['SCARlink corr'] < df['ArchR gene corr']).values] = -1\n",
    "    df['better_method_flag'] = better_method\n",
    "    df['corr_significance_log'] = df['corr_significance_log']*df['better_method_flag']\n",
    "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"#E6A0C4\", \"white\", \"#7294D4\"])\n",
    "    cmap1 = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"white\", \"#E6A0C4\"])\n",
    "    cmap2 = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"white\", \"#7294D4\"])\n",
    "    fig, ax = plt.subplots(1, 3, width_ratios=[1, 0.05, 0.05], figsize=(5.5, 3.5))\n",
    "    ax[0].scatter(df['ArchR gene corr'], df['SCARlink corr'], c=df['corr_significance_log'], cmap=cmap, alpha=0.8, vmin=-4, vmax=4, edgecolors='white', linewidth=0.7)\n",
    "    norm = plt.Normalize(-4, 4)\n",
    "    norm2 = plt.Normalize(0, 4)\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm) # \"BrBG\"\n",
    "    sm1 = plt.cm.ScalarMappable(cmap=cmap1, norm=norm2) # \"BrBG\"\n",
    "    sm2 = plt.cm.ScalarMappable(cmap=cmap2, norm=norm2) # \"BrBG\"\n",
    "    sm.set_array([])\n",
    "    sm1.set_array([])\n",
    "    sm2.set_array([])\n",
    "    fig.colorbar(sm1, cax=ax[1], orientation='vertical')\n",
    "    fig.colorbar(sm2, cax=ax[2], orientation='vertical')\n",
    "    ax[0].plot([min_val-0.01, max_val+0.01], [min_val-0.01, max_val+0.01], ls='--', color='black')\n",
    "    ax[0].set_xlim((min_val-0.01, max_val+0.01))\n",
    "    ax[0].set_ylim((min_val-0.01, max_val+0.01))\n",
    "    ax[0].set_xlabel(\"ArchR GSM correlation\")\n",
    "    ax[0].set_ylabel(\"SCARlink correlation\")\n",
    "    plt.suptitle(' '.join(plot_title.split('_')))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_prefix + '_compare_gsm.pdf', transparent=True)\n",
    "    plt.show()\n",
    "    \n",
    "    ###\n",
    "    print(\"SCARlink better:\", df[(df['SCARlink corr'] > df['ArchR gene corr']) & (pv < 0.05)].shape[0], df[(df['SCARlink corr'] > df['ArchR gene corr']) & (pv < 0.05)].shape[0]/df.shape[0], df.shape)\n",
    "    print(\"ArchR better:\", df[(df['SCARlink corr'] < df['ArchR gene corr']) & (pv < 0.05)].shape[0], df[(df['SCARlink corr'] < df['ArchR gene corr']) & (pv < 0.05)].shape[0]/df.shape[0], df.shape)\n",
    "    plt.close()\n",
    "    nan_vals = (~df['SCARlink corr'].isna()).values & (~df['ArchR gene corr'].isna()).values\n",
    "    _, pv = stats.wilcoxon(df['SCARlink corr'].values[nan_vals], df['ArchR gene corr'].values[nan_vals], alternative='greater')\n",
    "    print(\"Wilcoxon p-val:\", pv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47d2a5e7-8129-45ec-b794-6cb0aa630bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tmp directory\n",
    "os.makedirs(\"./tmp/\", exist_ok=True)\n",
    "os.makedirs(\"./scarlink_outs/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8f9e8d56-f5dd-4ac0-bcf5-447cad0c984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=make_scarlink_table_DiffTechs(dirname1='../mouse_brain_10X', dirname2='../mouse_brain_BGI', out_prefix='./corr', check_hvg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a358ea2-4bb1-4942-8c69-101e81b95ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diff']=df['method 2']-df['method 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "769c6935-8217-441d-b1c9-b068ea8a3a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "better_method_flag\n",
       " 1    229\n",
       "-1     80\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.better_method_flag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0db73624-49b3-4f87-89bb-bcaa1307a955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     -0.005808\n",
       "1     -0.066427\n",
       "2     -0.013940\n",
       "3     -0.051390\n",
       "4     -0.076000\n",
       "         ...   \n",
       "304   -0.131121\n",
       "305   -0.131385\n",
       "306   -0.076148\n",
       "307    0.023071\n",
       "308   -0.084262\n",
       "Name: diff, Length: 309, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acd2c221-3d42-4193-bc1e-b9df82e2851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=make_scarlink_table(dirname='../mouse_brain_10X', check_hvg=True)\n",
    "df2=make_scarlink_table(dirname='../mouse_brain_BGI', check_hvg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee503801-e7a7-4e82-85c1-3fad3889299a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25787602520779057"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['corr'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9e13f3b-244c-4021-bf10-6d47d06e7703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25235644153560394"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['corr'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ab632c6-5c43-45f2-8b35-e1939c431d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('./corr_values_10X.csv', sep='\\t', index=None)\n",
    "df2.to_csv('./corr_values_BGI.csv', sep='\\t', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eea845-ffaf-41bb-80f3-0477b7932cba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:scCAT]",
   "language": "python",
   "name": "conda-env-scCAT-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
